# Profile  
**Lee Jae Uk**  
Developer / Algorithm Learner  
---
## ğŸ§­ Summary  
- ì•Œê³ ë¦¬ì¦˜ í•™ìŠµê³¼ í•¨ê»˜ AI ë° ë°±ì—”ë“œ ê°œë°œ ì—­ëŸ‰ì„ í‚¤ìš°ê³  ìˆìŠµë‹ˆë‹¤.  
- FastAPIì™€ ONNX ê¸°ë°˜ ì‹¤ë¬´ ì—­ëŸ‰ì„ ìŒ“ê³  ìˆìœ¼ë©°,  
  ì´ë¡ ê³¼ ì‹¤ìŠµì„ ë³‘í–‰í•˜ë©° ê¹Šì´ ìˆëŠ” ê°œë°œìë¡œ ì„±ì¥í•˜ê³ ì ë…¸ë ¥í•©ë‹ˆë‹¤.  
- ìµœì‹  AI ë…¼ë¬¸ì„ ê¾¸ì¤€íˆ ì½ê³  êµ¬í˜„ì— ì ìš©í•´ë³´ë©°, ê°œë… ì •ë¦¬ì™€ ì‹¤í—˜ì„ ë³‘í–‰í•©ë‹ˆë‹¤.
---
## ğŸ›  Tech Stack
**Languages**  
ğŸ Python | â˜• Java | âš¡ C | â• C++ | ğŸŸ¨ JavaScript  

**Backend**  
ğŸƒ Spring Boot | âš¡ FastAPI | ğŸŸ¢ Node.js | ğŸ Django  

**AI/ML**  
ğŸ”¥ PyTorch | ğŸ§  TensorFlow | ğŸ¤— HuggingFace Transformers | ğŸš€ ONNX  

**Infra & Tools**  
ğŸ§ Linux | ğŸ“ Git | ğŸ³ Docker | ğŸŒ Nginx  

**Vector Search & MLOps**  
ğŸ¦œ LangChain | ğŸ¨ ChromaDB | ğŸ” FAISS | ğŸ“Š Vector DB  
---
## ğŸ“š Currently Studying
- âš¡ FastAPIë¥¼ í™œìš©í•œ REST API ì„¤ê³„ ë° ë°±ì—”ë“œ êµ¬í˜„  
- ğŸš€ ONNXë¡œ ëª¨ë¸ ì¶”ë¡  ìµœì í™” ë° ê²½ëŸ‰í™” ì‹¤í—˜  
- ğŸƒ Spring Boot MVC êµ¬ì¡° ë° ğŸƒ MongoDB ê¸°ë°˜ ì¸ì¦ ì‹œìŠ¤í…œ  
- ğŸ¤ Whisper ê¸°ë°˜ STT ëª¨ë¸ íŒŒì¸íŠœë‹ ë° ğŸ” RAG ì‹¤ìŠµ  
---
## ğŸ“– Papers I've Read
**Foundation Models & Architecture**
- ğŸ“„ [Attention Is All You Need (Vaswani et al., NeurIPS 2017)](https://arxiv.org/abs/1706.03762)  
  â†’ Transformer êµ¬ì¡°ì˜ ì›ì¡° ë…¼ë¬¸  
- ğŸ“„ [BERT: Pre-training of Deep Bidirectional Transformers (Devlin et al., NAACL 2019)](https://arxiv.org/abs/1810.04805)  
  â†’ ì–‘ë°©í–¥ ì–¸ì–´ ëª¨ë¸ì˜ í˜ì‹ ì  ì ‘ê·¼  
- ğŸ“„ [GPT-2: Language Models are Unsupervised Multitask Learners (Radford et al., 2019)](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)  
  â†’ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ë²”ìš©ì„± ì…ì¦  
- ğŸ“„ [RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al., 2019)](https://arxiv.org/abs/1907.11692)  
  â†’ BERT ìµœì í™” ë° ì„±ëŠ¥ ê°œì„  ì—°êµ¬  

**ğŸ” Retrieval-Augmented Generation (RAG) & Knowledge Systems** 
- ğŸ“„ [Retrieval-Augmented Generation for Knowledge-Intensive NLP (Lewis et al., NeurIPS 2020)](https://arxiv.org/abs/2005.11401)  
  â†’ RAG êµ¬ì¡° ì •ì˜ ë° Dense Passage Retrieval ë„ì…  
- ğŸ“„ [Dense Passage Retrieval for Open-Domain Question Answering (Karpukhin et al., EMNLP 2020)](https://arxiv.org/abs/2004.04906)  
  â†’ ë°€ì§‘ ë²¡í„° ê¸°ë°˜ ì •ë³´ ê²€ìƒ‰ ì‹œìŠ¤í…œ  
- ğŸ“„ [ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction (Khattab et al., SIGIR 2020)](https://arxiv.org/abs/2004.12832)  
  â†’ íš¨ìœ¨ì ì¸ ë¬¸ì„œ ê²€ìƒ‰ì„ ìœ„í•œ ëŠ¦ì€ ìƒí˜¸ì‘ìš© ëª¨ë¸  
- ğŸ“„ [FiD: Fusion-in-Decoder for Knowledge-Intensive NLP Tasks (Izacard & Grave, NeurIPS 2021)](https://arxiv.org/abs/2007.01282)  
  â†’ ë””ì½”ë”ì—ì„œ ë‹¤ì¤‘ ë¬¸ì„œ ìœµí•©ì„ í†µí•œ ì§€ì‹ ì§‘ì•½ì  NLP  
- ğŸ“„ [REALM: Retrieval-Augmented Language Model Pre-Training (Guu et al., ICML 2020)](https://arxiv.org/abs/2002.08909)  
  â†’ ì‚¬ì „ í›ˆë ¨ ë‹¨ê³„ì—ì„œ ê²€ìƒ‰ ê¸°ëŠ¥ í†µí•©  
- ğŸ“„ [RAG-Token vs RAG-Sequence: End-to-End Retrieval Approaches (Lewis et al., 2020)](https://arxiv.org/abs/2005.11401)  
  â†’ RAGì˜ ë‘ ê°€ì§€ ìƒì„± ë°©ì‹ ë¹„êµ ë¶„ì„  
- ğŸ“„ [RETRO: Improving Language Models by Retrieving from Trillions of Tokens (Borgeaud et al., ICML 2022)](https://arxiv.org/abs/2112.04426)  
  â†’ ëŒ€ê·œëª¨ í† í° ê²€ìƒ‰ì„ í†µí•œ ì–¸ì–´ ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒ  
- ğŸ“„ [Internet-Augmented Dialogue Generation (Komeili et al., ICML 2022)](https://arxiv.org/abs/2107.07566)  
  â†’ ì¸í„°ë„· ê²€ìƒ‰ ê¸°ë°˜ ëŒ€í™” ìƒì„± ì‹œìŠ¤í…œ  
- ğŸ“„ [WebGPT: Browser-assisted question-answering with human feedback (Nakano et al., 2021)](https://arxiv.org/abs/2112.09332)  
  â†’ ì›¹ ë¸Œë¼ìš°ì§• ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ  
- ğŸ“„ [LaMDA: Language Models for Dialog Applications (Thoppilan et al., 2022)](https://arxiv.org/abs/2201.08239)  
  â†’ ì™¸ë¶€ ì§€ì‹ í™œìš© ëŒ€í™” ëª¨ë¸  
- ğŸ“„ [Toolformer: Language Models Can Teach Themselves to Use Tools (Schick et al., NeurIPS 2023)](https://arxiv.org/abs/2302.04761)  
  â†’ ì–¸ì–´ ëª¨ë¸ì´ ìŠ¤ìŠ¤ë¡œ ë„êµ¬ ì‚¬ìš©ë²• í•™ìŠµ  
- ğŸ“„ [ReAct: Synergizing Reasoning and Acting in Language Models (Yao et al., ICLR 2023)](https://arxiv.org/abs/2210.03629)  
  â†’ ì¶”ë¡ ê³¼ í–‰ë™ì„ ê²°í•©í•œ ì–¸ì–´ ëª¨ë¸  
- ğŸ“„ [Langchain-Chatchat: Local Knowledge Base Q&A with RAG (2023)](https://github.com/chatchat-space/Langchain-Chatchat)  
  â†’ ë¡œì»¬ ì§€ì‹ë² ì´ìŠ¤ ê¸°ë°˜ RAG êµ¬í˜„  
- ğŸ“„ [RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval (Sarthi et al., 2024)](https://arxiv.org/abs/2401.18059)  
  â†’ íŠ¸ë¦¬ êµ¬ì¡° ê¸°ë°˜ ì¬ê·€ì  ì¶”ìƒí™” ê²€ìƒ‰ ì‹œìŠ¤í…œ  
- ğŸ“„ [Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection (Asai et al., 2023)](https://arxiv.org/abs/2310.11511)  
  â†’ ìê¸° ë°˜ì„±ì„ í†µí•œ RAG ì„±ëŠ¥ í–¥ìƒ  
- ğŸ“„ [HyDE: Precise Zero-Shot Dense Retrieval without Relevance Labels (Gao et al., ACL 2023)](https://arxiv.org/abs/2212.10496)  
  â†’ ê°€ìƒ ë¬¸ì„œ ìƒì„±ì„ í†µí•œ ì œë¡œìƒ· ê²€ìƒ‰  
- ğŸ“„ [RAFT: Adapting Language Model to Domain Specific RAG (Zhang et al., 2024)](https://arxiv.org/abs/2403.10131)  
  â†’ ë„ë©”ì¸ íŠ¹í™” RAG ì ì‘ ê¸°ë²•  
- ğŸ“„ [GraphRAG: Unlocking LLM discovery on narrative private data (Edge et al., 2024)](https://arxiv.org/abs/2404.16130)  
  â†’ ê·¸ë˜í”„ êµ¬ì¡°ë¥¼ í™œìš©í•œ RAG ì‹œìŠ¤í…œ  
- ğŸ“„ [MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries (Tang et al., 2024)](https://arxiv.org/abs/2401.15391)  
  â†’ ë‹¤ë‹¨ê³„ ì¶”ë¡ ì´ í•„ìš”í•œ RAG ë²¤ì¹˜ë§ˆí¬  
- ğŸ“„ [Lost in the Middle: How Language Models Use Long Contexts (Liu et al., 2023)](https://arxiv.org/abs/2307.03172)  
  â†’ ê¸´ ì»¨í…ìŠ¤íŠ¸ì—ì„œì˜ ì •ë³´ í™œìš© íŒ¨í„´ ë¶„ì„  
- ğŸ“„ [FLARE: Active Retrieval Augmented Generation (Jiang et al., 2023)](https://arxiv.org/abs/2305.06983)  
  â†’ ëŠ¥ë™ì  ê²€ìƒ‰ ê¸°ë°˜ ìƒì„± ëª¨ë¸  
- ğŸ“„ [Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity (Jeong et al., 2024)](https://arxiv.org/abs/2403.14403)  
  â†’ ì§ˆë¬¸ ë³µì¡ë„ì— ë”°ë¥¸ ì ì‘í˜• RAG  
- ğŸ“„ [Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models (Yu et al., 2023)](https://arxiv.org/abs/2311.09210)  
  â†’ ë…¸íŠ¸ ì²´ì¸ ë°©ì‹ì„ í†µí•œ RAG ê²¬ê³ ì„± í–¥ìƒ  

**ğŸ“Š Vector Search & Embedding Optimization**
- ğŸ“„ [Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks (Reimers & Gurevych, EMNLP 2019)](https://arxiv.org/abs/1908.10084)  
  â†’ ë¬¸ì¥ ì„ë² ë”© ìµœì í™”ë¥¼ ìœ„í•œ SBERT  
- ğŸ“„ [SimCSE: Simple Contrastive Learning of Sentence Embeddings (Gao et al., EMNLP 2021)](https://arxiv.org/abs/2104.08821)  
  â†’ ëŒ€ì¡° í•™ìŠµ ê¸°ë°˜ ë¬¸ì¥ ì„ë² ë”©  
- ğŸ“„ [E5: Text Embeddings by Weakly-Supervised Contrastive Pre-training (Wang et al., 2022)](https://arxiv.org/abs/2212.03533)  
  â†’ ì•½ì§€ë„ ëŒ€ì¡° ì‚¬ì „í›ˆë ¨ ê¸°ë°˜ í…ìŠ¤íŠ¸ ì„ë² ë”©  
- ğŸ“„ [BGE: BAAI General Embedding (Xiao et al., 2023)](https://arxiv.org/abs/2309.07597)  
  â†’ ë²”ìš© í…ìŠ¤íŠ¸ ì„ë² ë”© ëª¨ë¸  
- ğŸ“„ [Matryoshka Representation Learning (Kusupati et al., NeurIPS 2022)](https://arxiv.org/abs/2205.13147)  
  â†’ ë‹¤ì°¨ì› ì„ë² ë”© í‘œí˜„ í•™ìŠµ  

**âš¡ Efficient AI & Model Optimization**
- ğŸ“„ [LoRA: Low-Rank Adaptation of Large Language Models (Hu et al., ICLR 2022)](https://arxiv.org/abs/2106.09685)  
  â†’ LLM íŒŒì¸íŠœë‹ íš¨ìœ¨í™” ê¸°ìˆ   
- ğŸ“„ [DistilBERT: A distilled version of BERT (Sanh et al., 2019)](https://arxiv.org/abs/1910.01108)  
  â†’ BERT ëª¨ë¸ ê²½ëŸ‰í™” ê¸°ë²•  
- ğŸ“„ [MobileNetV2: Inverted Residuals and Linear Bottlenecks (Sandler et al., CVPR 2018)](https://arxiv.org/abs/1801.04381)  
  â†’ ê²½ëŸ‰ CNN êµ¬ì¡° ì´í•´ ë° ì˜ë£Œ AI ì ìš© ì‹¤í—˜  
- ğŸ“„ [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks (Tan et al., ICML 2019)](https://arxiv.org/abs/1905.11946)  
  â†’ ëª¨ë¸ í™•ì¥ ì „ëµ ë° íš¨ìœ¨ì  CNN ì„¤ê³„  
- ğŸ“„ [Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference (Jacob et al., CVPR 2018)](https://arxiv.org/abs/1712.05877)  
  â†’ ëª¨ë¸ ì–‘ìí™”ë¥¼ í†µí•œ ì¶”ë¡  ìµœì í™”  

**ğŸ‘ï¸ Computer Vision & Object Detection**
- ğŸ“„ [YOLOv8: Ultralytics Implementation (2023)](https://github.com/ultralytics/ultralytics)  
  â†’ ê°ì²´ íƒì§€ ìµœì‹  ëª¨ë¸ ì‹¤ì „ ì ìš©  
- ğŸ“„ [ResNet: Deep Residual Learning for Image Recognition (He et al., CVPR 2016)](https://arxiv.org/abs/1512.03385)  
  â†’ ì”ì°¨ ì—°ê²°ì„ í†µí•œ ê¹Šì€ ë„¤íŠ¸ì›Œí¬ í•™ìŠµ  
- ğŸ“„ [Vision Transformer: An Image is Worth 16x16 Words (Dosovitskiy et al., ICLR 2021)](https://arxiv.org/abs/2010.11929)  
  â†’ ì´ë¯¸ì§€ ì²˜ë¦¬ì— Transformer êµ¬ì¡° ì ìš©  

**ğŸ¤ Speech & Multimodal AI**
- ğŸ“„ [OpenAI Whisper: Robust Speech Recognition via Large-Scale Weak Supervision (Radford et al., 2022)](https://openai.com/research/whisper)  
  â†’ ëŒ€ê·œëª¨ ìŒì„± ë°ì´í„° í•™ìŠµ ê¸°ë°˜ STT ëª¨ë¸  
- ğŸ“„ [Wav2Vec 2.0: A Framework for Self-Supervised Learning of Speech Representations (Baevski et al., NeurIPS 2020)](https://arxiv.org/abs/2006.11477)  
  â†’ ìê¸°ì§€ë„ í•™ìŠµ ê¸°ë°˜ ìŒì„± í‘œí˜„ í•™ìŠµ  
- ğŸ“„ [CLIP: Learning Transferable Visual Representations from Natural Language Supervision (Radford et al., ICML 2021)](https://arxiv.org/abs/2103.00020)  
  â†’ ì‹œê°-ì–¸ì–´ ë©€í‹°ëª¨ë‹¬ í•™ìŠµ ëª¨ë¸  

**ğŸ“ Instruction Following & Advanced Training**
- ğŸ“„ [Instruction Tuning with GPT Models (OpenAI, 2023)](https://openai.com/research/instruction-following)  
  â†’ LLMì˜ Instruction ê¸°ë°˜ í•™ìŠµ ì›ë¦¬  
- ğŸ“„ [Constitutional AI: Harmlessness from AI Feedback (Bai et al., 2022)](https://arxiv.org/abs/2212.08073)  
  â†’ AI í”¼ë“œë°±ì„ í†µí•œ ì•ˆì „í•œ ëª¨ë¸ í•™ìŠµ  
- ğŸ“„ [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models (Wei et al., NeurIPS 2022)](https://arxiv.org/abs/2201.11903)  
  â†’ ë‹¨ê³„ë³„ ì¶”ë¡ ì„ í†µí•œ LLM ì„±ëŠ¥ í–¥ìƒ  
- ğŸ“„ [Prompt Engineering Guide (DAIR.AI)](https://github.com/dair-ai/Prompt-Engineering-Guide)  
  â†’ Prompt ì„¤ê³„ ì´ë¡ ê³¼ ì‹¤ìŠµ ì „ëµ ì •ë¦¬  

---
